{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a8ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48768ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date         high          low         open        close  \\\n",
      "0      1483228800  1003.080017   958.698975   963.658020   998.325012   \n",
      "1      1483315200  1031.390015   996.702026   998.617004  1021.750000   \n",
      "2      1483401600  1044.079956  1021.599976  1021.599976  1043.839966   \n",
      "3      1483488000  1159.420044  1044.400024  1044.400024  1154.729980   \n",
      "4      1483574400  1191.099976   910.416992  1156.729980  1013.380005   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "21725  1560038400     0.438784     0.381092     0.401229     0.387386   \n",
      "21726  1560124800     0.417566     0.383700     0.387073     0.416082   \n",
      "21727  1560211200     0.445997     0.403569     0.416230     0.435659   \n",
      "21728  1560297600     0.436418     0.421335     0.435659     0.427926   \n",
      "21729  1560384000     0.429957     0.411852     0.427878     0.414671   \n",
      "\n",
      "            volume     adjclose         p BTC-USD ETH-USD  ... XRP-USD  \\\n",
      "0      147775008.0   998.325012  0.381478    True   False  ...   False   \n",
      "1      222184992.0  1021.750000  0.220092    True   False  ...   False   \n",
      "2      185168000.0  1043.839966  0.202512    True   False  ...   False   \n",
      "3      344945984.0  1154.729980  1.259199    True   False  ...   False   \n",
      "4      510199008.0  1013.380005 -1.633140    True   False  ...   False   \n",
      "...            ...          ...       ...     ...     ...  ...     ...   \n",
      "21725    7705466.0     0.387386 -0.506457   False   False  ...   False   \n",
      "21726    3788821.0     0.416082  0.872468   False   False  ...   False   \n",
      "21727    3666843.0     0.435659  0.516341   False   False  ...   False   \n",
      "21728    2905098.0     0.427926 -0.295404   False   False  ...   False   \n",
      "21729    2163734.0     0.414671 -0.460656   False   False  ...   False   \n",
      "\n",
      "      DOGE-USD SHIB-USD AVAX-USD LTC-USD XMR-USD ETC-USD REP-USD MAID-USD  \\\n",
      "0        False    False    False   False   False   False   False    False   \n",
      "1        False    False    False   False   False   False   False    False   \n",
      "2        False    False    False   False   False   False   False    False   \n",
      "3        False    False    False   False   False   False   False    False   \n",
      "4        False    False    False   False   False   False   False    False   \n",
      "...        ...      ...      ...     ...     ...     ...     ...      ...   \n",
      "21725    False    False    False   False   False   False   False    False   \n",
      "21726    False    False    False   False   False   False   False    False   \n",
      "21727    False    False    False   False   False   False   False    False   \n",
      "21728    False    False    False   False   False   False   False    False   \n",
      "21729    False    False    False   False   False   False   False    False   \n",
      "\n",
      "      STEEM-USD  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "...         ...  \n",
      "21725      True  \n",
      "21726      True  \n",
      "21727      True  \n",
      "21728      True  \n",
      "21729      True  \n",
      "\n",
      "[11307 rows x 24 columns]              date         high          low         open        close  \\\n",
      "894    1560470400  8710.636719  8183.393066  8230.898438  8693.833008   \n",
      "895    1560556800  8859.127930  8618.395508  8689.746094  8838.375000   \n",
      "896    1560643200  9335.867188  8814.556641  8841.440430  8994.488281   \n",
      "897    1560729600  9416.407227  8988.923828  8988.923828  9320.352539   \n",
      "898    1560816000  9348.374023  9004.901367  9335.466797  9081.762695   \n",
      "...           ...          ...          ...          ...          ...   \n",
      "21993  1583193600     0.194391     0.177824     0.177824     0.184246   \n",
      "21994  1583280000     0.191703     0.180847     0.184246     0.187219   \n",
      "21995  1583366400     0.197155     0.187373     0.187373     0.194779   \n",
      "21996  1583452800     0.219489     0.193518     0.194779     0.219358   \n",
      "21997  1583539200     0.222903     0.204409     0.219279     0.215889   \n",
      "\n",
      "             volume     adjclose         p BTC-USD ETH-USD  ... XRP-USD  \\\n",
      "894    1.983116e+10  8693.833008  0.636852    True   False  ...   False   \n",
      "895    1.837103e+10  8838.375000  0.143727    True   False  ...   False   \n",
      "896    2.334855e+10  8994.488281  0.146327    True   False  ...   False   \n",
      "897    1.556295e+10  9320.352539  0.392772    True   False  ...   False   \n",
      "898    1.584821e+10  9081.762695 -0.414166    True   False  ...   False   \n",
      "...             ...          ...       ...     ...     ...  ...     ...   \n",
      "21993  3.075823e+06     0.184246  0.383242   False   False  ...   False   \n",
      "21994  2.302518e+06     0.187219  0.131532   False   False  ...   False   \n",
      "21995  1.939343e+06     0.194779  0.426218   False   False  ...   False   \n",
      "21996  2.604946e+06     0.219358  1.518107   False   False  ...   False   \n",
      "21997  2.549587e+06     0.215889 -0.266547   False   False  ...   False   \n",
      "\n",
      "      DOGE-USD SHIB-USD AVAX-USD LTC-USD XMR-USD ETC-USD REP-USD MAID-USD  \\\n",
      "894      False    False    False   False   False   False   False    False   \n",
      "895      False    False    False   False   False   False   False    False   \n",
      "896      False    False    False   False   False   False   False    False   \n",
      "897      False    False    False   False   False   False   False    False   \n",
      "898      False    False    False   False   False   False   False    False   \n",
      "...        ...      ...      ...     ...     ...     ...     ...      ...   \n",
      "21993    False    False    False   False   False   False   False    False   \n",
      "21994    False    False    False   False   False   False   False    False   \n",
      "21995    False    False    False   False   False   False   False    False   \n",
      "21996    False    False    False   False   False   False   False    False   \n",
      "21997    False    False    False   False   False   False   False    False   \n",
      "\n",
      "      STEEM-USD  \n",
      "894       False  \n",
      "895       False  \n",
      "896       False  \n",
      "897       False  \n",
      "898       False  \n",
      "...         ...  \n",
      "21993      True  \n",
      "21994      True  \n",
      "21995      True  \n",
      "21996      True  \n",
      "21997      True  \n",
      "\n",
      "[3388 rows x 24 columns]              date          high           low          open         close  \\\n",
      "1521   1614988800  49147.218750  47257.527344  48899.230469  48912.382812   \n",
      "1522   1615075200  51384.367188  48918.679688  48918.679688  51206.691406   \n",
      "1523   1615161600  52314.070312  49506.054688  51174.117188  52246.523438   \n",
      "1524   1615248000  54824.117188  51981.832031  52272.968750  54824.117188   \n",
      "1525   1615334400  57258.253906  53290.890625  54824.011719  56008.550781   \n",
      "...           ...           ...           ...           ...           ...   \n",
      "22620  1637712000      0.673348      0.607530      0.621976      0.612812   \n",
      "22621  1637798400      0.695432      0.623388      0.643072      0.631901   \n",
      "22622  1637884800      0.819299      0.673438      0.683161      0.702681   \n",
      "22623  1637971200      0.734130      0.674832      0.703990      0.706345   \n",
      "22624  1638078244      0.831198      0.738698      0.763668      0.759089   \n",
      "\n",
      "             volume      adjclose         p BTC-USD ETH-USD  ... XRP-USD  \\\n",
      "1521   3.436356e+10  48912.382812 -0.068379    True   False  ...   False   \n",
      "1522   4.313746e+10  51206.691406  0.517516    True   False  ...   False   \n",
      "1523   4.859743e+10  52246.523438  0.192260    True   False  ...   False   \n",
      "1524   5.091223e+10  54824.117188  0.543125    True   False  ...   False   \n",
      "1525   5.729558e+10  56008.550781  0.200452    True   False  ...   False   \n",
      "...             ...           ...       ...     ...     ...  ...     ...   \n",
      "22620  2.770215e+07      0.612812 -0.257400   False   False  ...   False   \n",
      "22621  4.556831e+07      0.631901 -0.290631   False   False  ...   False   \n",
      "22622  2.043422e+08      0.702681  0.288228   False   False  ...   False   \n",
      "22623  3.881345e+07      0.706345 -0.029620   False   False  ...   False   \n",
      "22624  1.514908e+08      0.759089 -0.147320   False   False  ...   False   \n",
      "\n",
      "      DOGE-USD SHIB-USD AVAX-USD LTC-USD XMR-USD ETC-USD REP-USD MAID-USD  \\\n",
      "1521     False    False    False   False   False   False   False    False   \n",
      "1522     False    False    False   False   False   False   False    False   \n",
      "1523     False    False    False   False   False   False   False    False   \n",
      "1524     False    False    False   False   False   False   False    False   \n",
      "1525     False    False    False   False   False   False   False    False   \n",
      "...        ...      ...      ...     ...     ...     ...     ...      ...   \n",
      "22620    False    False    False   False   False   False   False    False   \n",
      "22621    False    False    False   False   False   False   False    False   \n",
      "22622    False    False    False   False   False   False   False    False   \n",
      "22623    False    False    False   False   False   False   False    False   \n",
      "22624    False    False    False   False   False   False   False    False   \n",
      "\n",
      "      STEEM-USD  \n",
      "1521      False  \n",
      "1522      False  \n",
      "1523      False  \n",
      "1524      False  \n",
      "1525      False  \n",
      "...         ...  \n",
      "22620      True  \n",
      "22621      True  \n",
      "22622      True  \n",
      "22623      True  \n",
      "22624      True  \n",
      "\n",
      "[3388 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Replace with your own path\n",
    "df = pd.read_csv('/Users/timwu0/Documents/CS329P/afterhours_crypto/preprocessing/crypto_data.csv')\n",
    "coins = df['coin'].unique()\n",
    "# print(coins)\n",
    "\n",
    "#convert coin to one-hot vectors\n",
    "for coin in coins:\n",
    "    df[coin] = df['coin'] == coin\n",
    "\n",
    "def train_val_split(df, test_val_size, train_size):\n",
    "    train_data = pd.DataFrame(columns=df.columns)\n",
    "    val_data = pd.DataFrame(columns=df.columns)\n",
    "    test_data = pd.DataFrame(columns=df.columns)\n",
    "    for coin in coins:\n",
    "        df_coin = df.loc[df['coin'] == coin]\n",
    "        \n",
    "        split_train_val = int(train_size * len(df_coin))\n",
    "        split_val_test = split_train_val + int(test_val_size * len(df_coin))\n",
    "        \n",
    "        train_data = pd.concat([train_data, df_coin.iloc[:split_train_val]]) \n",
    "        val_data = pd.concat([val_data, df_coin.iloc[split_train_val:split_val_test]]) \n",
    "        test_data = pd.concat([test_data, df_coin.iloc[len(df_coin) - int(test_val_size * len(df_coin)):]])\n",
    "        # print(train_data.tail())\n",
    "    \n",
    "    # print(train_data.columns)\n",
    "    mean_p = train_data['p'].mean()\n",
    "    std_p = train_data['p'].std()\n",
    "    train_data['p'] = ((train_data['p']-mean_p)/std_p)#.round(1)\n",
    "    val_data['p'] = ((val_data['p']-mean_p)/std_p)#.round(1)\n",
    "    test_data['p'] = ((test_data['p']-mean_p)/std_p)#.round(1)\n",
    "    \n",
    "\n",
    "    return train_data.drop(['coin'], axis=1), val_data.drop(['coin'], axis=1), test_data.drop(['coin'], axis=1)\n",
    "train, val, test = train_val_split(df, 0.15, 0.5)\n",
    "print(train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88fbb631",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_len = 22\n",
    "test_val_size = 0.15\n",
    "\n",
    "def extract_window_data(df, window_len):\n",
    "    window_data = []\n",
    "    \n",
    "    for idx in range(len(df) - window_len):\n",
    "        tmp = df[idx: (idx + window_len)].copy()\n",
    "        \n",
    "        window_data.append(tmp.values)\n",
    "    return np.array(window_data)\n",
    "\n",
    "def prepare_data(df, target_col, window_len, test_val_size, train_size):\n",
    "    train_data, val_data, test_data = train_val_split(df, test_val_size=test_val_size, train_size=train_size)\n",
    "    # print(train_data.shape)\n",
    "    x_train = extract_window_data(train_data, window_len)\n",
    "    # print(X_train.shape)\n",
    "    x_val = extract_window_data(val_data, window_len) \n",
    "    x_test = extract_window_data(test_data, window_len)\n",
    "    \n",
    "    y_train = train_data[target_col][window_len:].values\n",
    "    y_val = val_data[target_col][window_len:].values\n",
    "    y_test = test_data[target_col][window_len:].values\n",
    "\n",
    "    #print(len(train_data[target_col][:-window_len].values-1))\n",
    "    #print(len(y_train))\n",
    "    \n",
    "    # print(X_train, y_train)\n",
    "\n",
    "    return train_data, val_data, test_data, x_train, x_val, x_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2337c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=5\n",
    "loss='mse'\n",
    "optimizer = 'adam'\n",
    "dropout=0.9\n",
    "num_layers=4\n",
    "cell_size=32\n",
    "dense_units=95\n",
    "technicals=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d379f251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4, 0.47500000000000003, 0.55, 0.625, 0.7000000000000001]\n"
     ]
    }
   ],
   "source": [
    "folds=5\n",
    "min_train_size=0.4\n",
    "test_val_size=0.15\n",
    "\n",
    "train_sizes = []\n",
    "for k in range(folds):\n",
    "    train_sizes.append(min_train_size + k / (folds - 1) * (1 - (2 * test_val_size + min_train_size)))\n",
    "print(train_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9851ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of fold train data: (9020, 22, 24) (9020, 1)\n",
      "Epoch 1/5\n",
      "282/282 [==============================] - 9s 20ms/step - loss: 1.0160\n",
      "Epoch 2/5\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 1.0024\n",
      "Epoch 3/5\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 1.0021\n",
      "Epoch 4/5\n",
      "282/282 [==============================] - 6s 22ms/step - loss: 1.0019\n",
      "Epoch 5/5\n",
      "282/282 [==============================] - 6s 21ms/step - loss: 1.0014\n",
      "Preds:  (3366,) [[7.150167e-07]\n",
      " [7.150167e-07]\n",
      " [7.150167e-07]\n",
      " ...\n",
      " [5.517112e-07]\n",
      " [5.517112e-07]\n",
      " [5.517112e-07]]\n",
      "Fold number 1 MSE:  0.3719660012690479\n",
      "Size of fold train data: (10715, 22, 24) (10715, 1)\n",
      "Epoch 1/5\n",
      "335/335 [==============================] - 9s 20ms/step - loss: 1.0165\n",
      "Epoch 2/5\n",
      "335/335 [==============================] - 7s 20ms/step - loss: 1.0011\n",
      "Epoch 3/5\n",
      "335/335 [==============================] - 7s 20ms/step - loss: 1.0015\n",
      "Epoch 4/5\n",
      "335/335 [==============================] - 7s 20ms/step - loss: 1.0016\n",
      "Epoch 5/5\n",
      "335/335 [==============================] - 7s 20ms/step - loss: 1.0011\n",
      "Preds:  (3366,) [[2.7805484e-07]\n",
      " [2.7805484e-07]\n",
      " [2.7805484e-07]\n",
      " ...\n",
      " [2.0783817e-07]\n",
      " [2.0783817e-07]\n",
      " [2.0783817e-07]]\n",
      "Fold number 2 MSE:  0.4252373434548543\n",
      "Size of fold train data: (12409, 22, 24) (12409, 1)\n",
      "Epoch 1/5\n",
      "388/388 [==============================] - 10s 20ms/step - loss: 1.0161\n",
      "Epoch 2/5\n",
      "388/388 [==============================] - 8s 21ms/step - loss: 1.0017\n",
      "Epoch 3/5\n",
      "388/388 [==============================] - 8s 20ms/step - loss: 1.0009\n",
      "Epoch 4/5\n",
      "388/388 [==============================] - 8s 20ms/step - loss: 1.0012\n",
      "Epoch 5/5\n",
      "388/388 [==============================] - 8s 20ms/step - loss: 1.0008\n",
      "Preds:  (3366,) [[3.4859630e-07]\n",
      " [3.4878252e-07]\n",
      " [3.4888564e-07]\n",
      " ...\n",
      " [2.8986898e-07]\n",
      " [2.8989137e-07]\n",
      " [2.8992122e-07]]\n",
      "Fold number 3 MSE:  0.6127803856208579\n",
      "Size of fold train data: (14115, 22, 24) (14115, 1)\n",
      "Epoch 1/5\n",
      "442/442 [==============================] - 12s 21ms/step - loss: 1.0118\n",
      "Epoch 2/5\n",
      "442/442 [==============================] - 9s 21ms/step - loss: 1.0018\n",
      "Epoch 3/5\n",
      "442/442 [==============================] - 9s 20ms/step - loss: 1.0007\n",
      "Epoch 4/5\n",
      "442/442 [==============================] - 9s 21ms/step - loss: 1.0005\n",
      "Epoch 5/5\n",
      "442/442 [==============================] - 9s 20ms/step - loss: 1.0007\n",
      "Preds:  (3366,) [[1.3776308e-07]\n",
      " [1.4216977e-07]\n",
      " [1.4775185e-07]\n",
      " ...\n",
      " [1.2138109e-07]\n",
      " [1.2138109e-07]\n",
      " [1.2138109e-07]]\n",
      "Fold number 4 MSE:  0.6248043913791425\n",
      "Size of fold train data: (15810, 22, 24) (15810, 1)\n",
      "Epoch 1/5\n",
      "495/495 [==============================] - 13s 22ms/step - loss: 1.0140\n",
      "Epoch 2/5\n",
      "495/495 [==============================] - 10s 21ms/step - loss: 1.0006\n",
      "Epoch 3/5\n",
      "495/495 [==============================] - 10s 20ms/step - loss: 1.0006\n",
      "Epoch 4/5\n",
      "495/495 [==============================] - 10s 20ms/step - loss: 1.0007\n",
      "Epoch 5/5\n",
      "495/495 [==============================] - 10s 20ms/step - loss: 1.0006\n",
      "Preds:  (3366,) [[1.8269597e-08]\n",
      " [1.8269597e-08]\n",
      " [1.8269597e-08]\n",
      " ...\n",
      " [1.7356198e-08]\n",
      " [1.7307274e-08]\n",
      " [1.7335291e-08]]\n",
      "Fold number 5 MSE:  0.8777286997784839\n",
      "Best fold is fold number 1 \n",
      " Training on best fold...\n",
      "Epoch 1/5\n",
      "282/282 [==============================] - 8s 20ms/step - loss: 1.0175\n",
      "Epoch 2/5\n",
      "282/282 [==============================] - 7s 24ms/step - loss: 1.0018\n",
      "Epoch 3/5\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 1.0021\n",
      "Epoch 4/5\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 1.0020\n",
      "Epoch 5/5\n",
      "282/282 [==============================] - 6s 20ms/step - loss: 1.0011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd4a5313e80>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rnn_model import rnn\n",
    "\n",
    "min_MSE = 999# np.float(inf)\n",
    "min_MSE_k = 0\n",
    "for i, train_size in enumerate(train_sizes):\n",
    "    train, val, test, x_train, x_val, x_test, y_train, y_val, y_test = prepare_data(df, 'p', window_len=window_len, test_val_size=test_val_size, train_size=train_size)\n",
    "\n",
    "    features = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "    labels = tf.expand_dims(tf.convert_to_tensor(y_train, dtype=tf.float32), axis=1)\n",
    "    print('Size of fold train data:', features.shape, labels.shape)\n",
    "    model = rnn(features=features, \n",
    "            labels=labels, \n",
    "            dropout=dropout, \n",
    "            num_layers=num_layers, \n",
    "            cell_size=cell_size, \n",
    "            dense_units=dense_units,\n",
    "            technicals=technicals)\n",
    "    model.fit(features, labels, epochs=epochs, shuffle=True)\n",
    "    preds = model.predict(tf.convert_to_tensor(x_val, dtype=tf.float32))\n",
    "    MSE = ((preds - y_val) ** 2).mean()\n",
    "    print('Preds: ', y_val.shape, preds)\n",
    "    if MSE < min_MSE:\n",
    "        min_MSE = min(min_MSE, MSE)\n",
    "        min_MSE_k = i + 1\n",
    "        \n",
    "    print('Fold number', i + 1, 'MSE: ', MSE)\n",
    "    \n",
    "# Use train data from best fold  \n",
    "print('Best fold is fold number', min_MSE_k, '\\n Training on best fold...')\n",
    "train, val, test, x_train, x_val, x_test, y_train, y_val, y_test = prepare_data(df, 'p', window_len=window_len, test_val_size=test_val_size, train_size=train_sizes[min_MSE_k-1])\n",
    "features = tf.convert_to_tensor(x_train, dtype=tf.float32)\n",
    "labels = tf.expand_dims(tf.convert_to_tensor(y_train, dtype=tf.float32), axis=1)\n",
    "\n",
    "model = rnn(features=features, \n",
    "        labels=labels, \n",
    "        dropout=dropout, \n",
    "        num_layers=num_layers, \n",
    "        cell_size=cell_size, \n",
    "        dense_units=dense_units,\n",
    "        technicals=technicals)\n",
    "model.fit(features, labels, epochs=epochs, shuffle=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dfd1123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]\n",
      " [8.021305e-07]]\n",
      "[-0.07353904  0.31122752  0.16983725 -0.07073357 -0.03459343 -0.01152111\n",
      " -0.42432464  0.16760582 -0.00887296 -0.26355775 -0.50141994  0.3988012\n",
      " -0.08492495  0.24302001  0.00220371 -0.12377299  0.64265636 -0.14526744\n",
      " -0.0238203  -0.38251732]\n",
      "-0.02146501941191319 5.637405e-07 -0.021465583152434017\n",
      "MAE:  0.5648923171824302\n",
      "MSE:  0.7465080041575733\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(tf.convert_to_tensor(x_test, dtype=tf.float32))\n",
    "\n",
    "print(preds[:20])\n",
    "print(y_test[:20])\n",
    "\n",
    "print(y_test.mean(), preds.mean(), (y_test - preds).mean())\n",
    "\n",
    "print('MAE: ', (np.absolute(preds - y_test)).mean())\n",
    "print('MSE: ', ((preds - y_test) ** 2).mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
